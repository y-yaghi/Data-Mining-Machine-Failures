{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d09eec",
   "metadata": {},
   "source": [
    "# Predictive Maintenance Classification Workflow\n",
    "## With loading if data already available to avoid redoing work - starts from full_normalized CSV with smote already included\n",
    "\n",
    "This Jupyter notebook provides a streamlined, organized pipeline for training and loading ML models to predict machine failures. It includes:\n",
    "\n",
    "- Data loading and preprocessing\n",
    "- Baseline and tuned model training (Decision Tree, Random Forest, XGBoost on GPU)\n",
    "- Pretrained model loading and saving into `TrainedModels/`\n",
    "- Model evaluation and visualization with detailed metrics\n",
    "- XGBoost threshold tuning and CSV export for visualization\n",
    "- Summary of model performance saved to CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60971eb3",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n",
    "\n",
    "Import necessary libraries and configure warnings, plotting, and the model save directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23350341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:37.040028Z",
     "iopub.status.busy": "2025-04-25T16:43:37.040028Z",
     "iopub.status.idle": "2025-04-25T16:43:39.017328Z",
     "shell.execute_reply": "2025-04-25T16:43:39.017328Z",
     "shell.execute_reply.started": "2025-04-25T16:43:37.040028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: TrainedModels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    recall_score, precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "SAVE_DIR = \"TrainedModels\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Model directory: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3a7d3",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preparation\n",
    "\n",
    "Load the normalized dataset, select relevant features, and split into train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7864dd13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:39.018332Z",
     "iopub.status.busy": "2025-04-25T16:43:39.018332Z",
     "iopub.status.idle": "2025-04-25T16:43:39.219712Z",
     "shell.execute_reply": "2025-04-25T16:43:39.219712Z",
     "shell.execute_reply.started": "2025-04-25T16:43:39.018332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test shapes: (15443, 3) (3861, 3)\n"
     ]
    }
   ],
   "source": [
    "dtype_dict = {\n",
    "    'norm_power': 'float32',\n",
    "    'norm_temp_diff': 'float32',\n",
    "    'norm_tool_wear_adjusted': 'float32',\n",
    "    'Bool_MF': 'bool'\n",
    "}\n",
    "use_columns = list(dtype_dict.keys())\n",
    "\n",
    "data = pd.read_csv(\"full_normalized.csv\", dtype=dtype_dict, usecols=use_columns)\n",
    "data['Bool_MF_int'] = data['Bool_MF'].astype('int8')\n",
    "X = data[['norm_power', 'norm_temp_diff', 'norm_tool_wear_adjusted']]\n",
    "y = data['Bool_MF_int']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train/test shapes:\", X_train.shape, X_test.shape)\n",
    "gc.collect()\n",
    "DTRAIN = xgb.DMatrix(X_train, label=y_train)\n",
    "DTEST  = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46105b4",
   "metadata": {},
   "source": [
    "## 3. Helper Functions \n",
    "\n",
    "Functions to save models and evaluate both sklearn and XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4016aa51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:39.221220Z",
     "iopub.status.busy": "2025-04-25T16:43:39.221220Z",
     "iopub.status.idle": "2025-04-25T16:43:39.230082Z",
     "shell.execute_reply": "2025-04-25T16:43:39.229077Z",
     "shell.execute_reply.started": "2025-04-25T16:43:39.221220Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(obj, fname):\n",
    "    path = os.path.join(SAVE_DIR, fname)\n",
    "    if hasattr(obj, 'save_model'):\n",
    "        obj.save_model(path)\n",
    "    else:\n",
    "        joblib.dump(obj, path)\n",
    "    print(f\"Saved {fname}\")\n",
    "\n",
    "\n",
    "def evaluate_sklearn(model, name, X_tr, y_tr, X_te, y_te):\n",
    "    train_pred = model.predict(X_tr)\n",
    "    test_pred = model.predict(X_te)\n",
    "    train_acc = accuracy_score(y_tr, train_pred)\n",
    "    test_acc = accuracy_score(y_te, test_pred)\n",
    "    cv_mean = cross_val_score(model, X_tr, y_tr, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"{name} - Training Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"{name} - Test Accuracy:      {test_acc:.4f}\")\n",
    "    print(f\"{name} CV Mean Score:       {cv_mean:.6f}\\n\")\n",
    "    print(f\"{name} Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_te, test_pred), \"\\n\")\n",
    "    print(f\"{name} Classification Report (Test):\")\n",
    "    print(classification_report(y_te, test_pred))\n",
    "\n",
    "\n",
    "def evaluate_xgb(booster, name, dtr, DTE, y_tr, y_te):\n",
    "    tr_proba = booster.predict(dtr, iteration_range=(0, booster.best_iteration+1))\n",
    "    te_proba = booster.predict(DTE, iteration_range=(0, booster.best_iteration+1))\n",
    "    tr_pred = (tr_proba >= 0.5).astype(int)\n",
    "    te_pred = (te_proba >= 0.5).astype(int)\n",
    "    tr_acc = accuracy_score(y_tr, tr_pred)\n",
    "    te_acc = accuracy_score(y_te, te_pred)\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"{name} - Training Accuracy: {tr_acc:.4f}\")\n",
    "    print(f\"{name} - Test Accuracy:      {te_acc:.4f}\\n\")\n",
    "    print(f\"{name} Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_te, te_pred), \"\\n\")\n",
    "    print(f\"{name} Classification Report (Test):\")\n",
    "    print(classification_report(y_te, te_pred))\n",
    "    return te_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4b6ba",
   "metadata": {},
   "source": [
    "## 4. Decision Tree: Baseline and Tuned\n",
    "\n",
    "Load or train baseline DT, then load or train tuned DT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8b8bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:39.231081Z",
     "iopub.status.busy": "2025-04-25T16:43:39.231081Z",
     "iopub.status.idle": "2025-04-25T16:43:42.274161Z",
     "shell.execute_reply": "2025-04-25T16:43:42.274161Z",
     "shell.execute_reply.started": "2025-04-25T16:43:39.231081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Decision Tree ---\n",
      "Baseline Decision Tree - Training Accuracy: 1.0000\n",
      "Baseline Decision Tree - Test Accuracy:      0.9321\n",
      "Baseline Decision Tree CV Mean Score:       0.919187\n",
      "\n",
      "Baseline Decision Tree Confusion Matrix (Test):\n",
      "[[1844  132]\n",
      " [ 130 1755]] \n",
      "\n",
      "Baseline Decision Tree Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1976\n",
      "           1       0.93      0.93      0.93      1885\n",
      "\n",
      "    accuracy                           0.93      3861\n",
      "   macro avg       0.93      0.93      0.93      3861\n",
      "weighted avg       0.93      0.93      0.93      3861\n",
      "\n",
      "--- Tuned Decision Tree ---\n",
      "Tuned Decision Tree - Training Accuracy: 0.9277\n",
      "Tuned Decision Tree - Test Accuracy:      0.9073\n",
      "Tuned Decision Tree CV Mean Score:       0.899696\n",
      "\n",
      "Tuned Decision Tree Confusion Matrix (Test):\n",
      "[[1804  172]\n",
      " [ 186 1699]] \n",
      "\n",
      "Tuned Decision Tree Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      1976\n",
      "           1       0.91      0.90      0.90      1885\n",
      "\n",
      "    accuracy                           0.91      3861\n",
      "   macro avg       0.91      0.91      0.91      3861\n",
      "weighted avg       0.91      0.91      0.91      3861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT_BASE = \"DecisionTree_baseline.pkl\"\n",
    "if os.path.exists(os.path.join(SAVE_DIR, DT_BASE)):\n",
    "    dt_baseline = joblib.load(os.path.join(SAVE_DIR, DT_BASE))\n",
    "else:\n",
    "    dt_baseline = DecisionTreeClassifier(random_state=42)\n",
    "    dt_baseline.fit(X_train, y_train)\n",
    "    save_model(dt_baseline, DT_BASE)\n",
    "# Evaluate\n",
    "evaluate_sklearn(dt_baseline, \"Baseline Decision Tree\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Tuned\n",
    "DT_TUNED = \"DecisionTree_best.pkl\"\n",
    "if os.path.exists(os.path.join(SAVE_DIR, DT_TUNED)):\n",
    "    best_dt = joblib.load(os.path.join(SAVE_DIR, DT_TUNED))\n",
    "else:\n",
    "    grid = {\n",
    "        'max_depth': [6, 8, 10], 'min_samples_split': [5, 10, 15],\n",
    "        'min_samples_leaf': [2, 4, 5, 7], 'criterion': ['gini', 'entropy'],\n",
    "        'ccp_alpha': [0.0, 0.001, 0.01]\n",
    "    }\n",
    "    dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), grid, cv=5,\n",
    "                           scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "    dt_grid.fit(X_train, y_train)\n",
    "    best_dt = dt_grid.best_estimator_\n",
    "    save_model(best_dt, DT_TUNED)\n",
    "# Evaluate\n",
    "evaluate_sklearn(best_dt, \"Tuned Decision Tree\", X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9255132",
   "metadata": {},
   "source": [
    "## 5. Random Forest: Baseline and Tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba490de1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:42.275166Z",
     "iopub.status.busy": "2025-04-25T16:43:42.275166Z",
     "iopub.status.idle": "2025-04-25T16:43:45.863827Z",
     "shell.execute_reply": "2025-04-25T16:43:45.863827Z",
     "shell.execute_reply.started": "2025-04-25T16:43:42.275166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Random Forest ---\n",
      "Baseline Random Forest - Training Accuracy: 1.0000\n",
      "Baseline Random Forest - Test Accuracy:      0.9358\n",
      "Baseline Random Forest CV Mean Score:       0.934339\n",
      "\n",
      "Baseline Random Forest Confusion Matrix (Test):\n",
      "[[1845  131]\n",
      " [ 117 1768]] \n",
      "\n",
      "Baseline Random Forest Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1976\n",
      "           1       0.93      0.94      0.93      1885\n",
      "\n",
      "    accuracy                           0.94      3861\n",
      "   macro avg       0.94      0.94      0.94      3861\n",
      "weighted avg       0.94      0.94      0.94      3861\n",
      "\n",
      "--- Tuned Random Forest ---\n",
      "Tuned Random Forest - Training Accuracy: 0.9915\n",
      "Tuned Random Forest - Test Accuracy:      0.9308\n",
      "Tuned Random Forest CV Mean Score:       0.931231\n",
      "\n",
      "Tuned Random Forest Confusion Matrix (Test):\n",
      "[[1841  135]\n",
      " [ 132 1753]] \n",
      "\n",
      "Tuned Random Forest Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1976\n",
      "           1       0.93      0.93      0.93      1885\n",
      "\n",
      "    accuracy                           0.93      3861\n",
      "   macro avg       0.93      0.93      0.93      3861\n",
      "weighted avg       0.93      0.93      0.93      3861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "RF_BASE = \"RandomForest_baseline.pkl\"\n",
    "if os.path.exists(os.path.join(SAVE_DIR, RF_BASE)):\n",
    "    rf_baseline = joblib.load(os.path.join(SAVE_DIR, RF_BASE))\n",
    "else:\n",
    "    rf_baseline = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    rf_baseline.fit(X_train, y_train)\n",
    "    save_model(rf_baseline, RF_BASE)\n",
    "# Evaluate\n",
    "evaluate_sklearn(rf_baseline, \"Baseline Random Forest\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Tuned\n",
    "RF_TUNED = \"RandomForest_best.pkl\"\n",
    "if os.path.exists(os.path.join(SAVE_DIR, RF_TUNED)):\n",
    "    best_rf = joblib.load(os.path.join(SAVE_DIR, RF_TUNED))\n",
    "else:\n",
    "    from scipy.stats import randint\n",
    "    dist = {'n_estimators': randint(50,200), 'max_depth': randint(3,20),\n",
    "            'min_samples_split': randint(2,10), 'min_samples_leaf': randint(1,4)}\n",
    "    rf_search = RandomizedSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                                    dist, n_iter=20, cv=5, random_state=42,\n",
    "                                    n_jobs=-1, verbose=1)\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    best_rf = rf_search.best_estimator_\n",
    "    save_model(best_rf, RF_TUNED)\n",
    "# Evaluate\n",
    "evaluate_sklearn(best_rf, \"Tuned Random Forest\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da446b",
   "metadata": {},
   "source": [
    "## 6. XGBoost (GPU): Baseline and Tuned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fda490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:45.864832Z",
     "iopub.status.busy": "2025-04-25T16:43:45.864832Z",
     "iopub.status.idle": "2025-04-25T16:43:45.984519Z",
     "shell.execute_reply": "2025-04-25T16:43:45.984519Z",
     "shell.execute_reply.started": "2025-04-25T16:43:45.864832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline XGBoost ---\n",
      "Baseline XGBoost - Training Accuracy: 0.9964\n",
      "Baseline XGBoost - Test Accuracy:      0.9808\n",
      "\n",
      "Baseline XGBoost Confusion Matrix (Test):\n",
      "[[1944   32]\n",
      " [  42 1843]] \n",
      "\n",
      "Baseline XGBoost Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1976\n",
      "           1       0.98      0.98      0.98      1885\n",
      "\n",
      "    accuracy                           0.98      3861\n",
      "   macro avg       0.98      0.98      0.98      3861\n",
      "weighted avg       0.98      0.98      0.98      3861\n",
      "\n",
      "--- Tuned XGBoost ---\n",
      "Tuned XGBoost - Training Accuracy: 0.9922\n",
      "Tuned XGBoost - Test Accuracy:      0.9788\n",
      "\n",
      "Tuned XGBoost Confusion Matrix (Test):\n",
      "[[1932   44]\n",
      " [  38 1847]] \n",
      "\n",
      "Tuned XGBoost Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1976\n",
      "           1       0.98      0.98      0.98      1885\n",
      "\n",
      "    accuracy                           0.98      3861\n",
      "   macro avg       0.98      0.98      0.98      3861\n",
      "weighted avg       0.98      0.98      0.98      3861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Baseline\n",
    "XGB_BASE = \"XGBoost_baseline.json\"\n",
    "base_params = {'objective':'binary:logistic','eval_metric':'logloss',\n",
    "               'tree_method':'gpu_hist','predictor':'gpu_predictor'}\n",
    "if os.path.exists(os.path.join(SAVE_DIR, XGB_BASE)):\n",
    "    xgb_baseline = xgb.Booster()\n",
    "    xgb_baseline.load_model(os.path.join(SAVE_DIR, XGB_BASE))\n",
    "else:\n",
    "    xgb_baseline = xgb.train(base_params, DTRAIN, num_boost_round=200,\n",
    "                              evals=[(DTEST,'eval')], early_stopping_rounds=10,\n",
    "                              verbose_eval=False)\n",
    "    save_model(xgb_baseline, XGB_BASE)\n",
    "# Evaluate\n",
    "_ = evaluate_xgb(xgb_baseline, \"Baseline XGBoost\", DTRAIN, DTEST, y_train, y_test)\n",
    "\n",
    "# Tuned\n",
    "XGB_TUNED = \"XGBoost_best.json\"\n",
    "if os.path.exists(os.path.join(SAVE_DIR, XGB_TUNED)):\n",
    "    best_xgb = xgb.Booster()\n",
    "    best_xgb.load_model(os.path.join(SAVE_DIR, XGB_TUNED))\n",
    "else:\n",
    "    from sklearn.model_selection import RepeatedKFold\n",
    "    from xgboost import XGBClassifier\n",
    "    param_dist = {\n",
    "        'n_estimators':[100,150,200,250,300],'max_depth':[4,6,8,10],\n",
    "        'learning_rate':[0.01,0.05,0.1,0.15],'subsample':[0.7,0.8,0.9,1.0],\n",
    "        'colsample_bytree':[0.7,0.8,0.9,1.0],'gamma':[0,0.1,0.5,1],\n",
    "        'reg_alpha':[0,0.01,0.1,1],'reg_lambda':[1,1.5,2,3]\n",
    "    }\n",
    "    xgb_clf = XGBClassifier(**base_params, random_state=42)\n",
    "    rkf = RepeatedKFold(n_splits=5,n_repeats=2,random_state=42)\n",
    "    xgb_search = RandomizedSearchCV(xgb_clf, param_dist, n_iter=30,\n",
    "                                    scoring='accuracy', cv=rkf,\n",
    "                                    n_jobs=1, random_state=42, verbose=1)\n",
    "    xgb_search.fit(X_train, y_train)\n",
    "    params = xgb_search.best_params_.copy(); params.update(base_params)\n",
    "    rounds = params.pop('n_estimators',200)\n",
    "    best_xgb = xgb.train(params, DTRAIN, num_boost_round=rounds,\n",
    "                         evals=[(DTEST,'eval')], early_stopping_rounds=10,\n",
    "                         verbose_eval=False)\n",
    "    save_model(best_xgb, XGB_TUNED)\n",
    "# Evaluate\n",
    "probas_best = evaluate_xgb(best_xgb, \"Tuned XGBoost\", DTRAIN, DTEST, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877bd8c0",
   "metadata": {},
   "source": [
    "## 7. XGBoost Threshold Tuning & Export\n",
    "\n",
    "Scan multiple thresholds, save results for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbe0b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:45.986030Z",
     "iopub.status.busy": "2025-04-25T16:43:45.985525Z",
     "iopub.status.idle": "2025-04-25T16:43:46.054735Z",
     "shell.execute_reply": "2025-04-25T16:43:46.054232Z",
     "shell.execute_reply.started": "2025-04-25T16:43:45.986030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold tuning data saved.\n"
     ]
    }
   ],
   "source": [
    "thresholds=[0.1,0.15,0.2,0.25,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "records=[]\n",
    "for th in thresholds:\n",
    "    preds = (probas_best>=th).astype(int)\n",
    "    records.append({\n",
    "        'threshold':th,\n",
    "        'accuracy':accuracy_score(y_test,preds),\n",
    "        'precision':precision_score(y_test,preds),\n",
    "        'recall':recall_score(y_test,preds)\n",
    "    })\n",
    "thresh_df = pd.DataFrame(records)\n",
    "thresh_df.to_csv(os.path.join(SAVE_DIR,'xgb_threshold_tuning.csv'),index=False)\n",
    "print(\"Threshold tuning data saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401e95f",
   "metadata": {},
   "source": [
    "## 8. Model Performance Summary & Export\n",
    "Compile a summary of all models and export for dashboarding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a798dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T16:43:46.056242Z",
     "iopub.status.busy": "2025-04-25T16:43:46.055237Z",
     "iopub.status.idle": "2025-04-25T16:43:46.175252Z",
     "shell.execute_reply": "2025-04-25T16:43:46.175252Z",
     "shell.execute_reply.started": "2025-04-25T16:43:46.056242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance summary saved.\n"
     ]
    }
   ],
   "source": [
    "models_summary = []\n",
    "entries = [\n",
    "    ('DT Baseline', dt_baseline.predict(X_test)),\n",
    "    ('DT Tuned',    best_dt.predict(X_test)),\n",
    "    ('RF Baseline', rf_baseline.predict(X_test)),\n",
    "    ('RF Tuned',    best_rf.predict(X_test)),\n",
    "    ('XGB Baseline', (xgb_baseline.predict(DTEST)>=0.5).astype(int)),\n",
    "    ('XGB Tuned',   (probas_best>=0.5).astype(int))\n",
    "]\n",
    "for name, preds in entries:\n",
    "    models_summary.append({\n",
    "        'model':name,\n",
    "        'accuracy':accuracy_score(y_test,preds),\n",
    "        'precision':precision_score(y_test,preds),\n",
    "        'recall':recall_score(y_test,preds)\n",
    "    })\n",
    "summary_df = pd.DataFrame(models_summary)\n",
    "summary_df.to_csv(os.path.join(SAVE_DIR,'model_performance_summary.csv'),index=False)\n",
    "print(\"Performance summary saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637babbc",
   "metadata": {},
   "source": [
    "## **Workflow complete!** Use CSVs for plotting/dashboarding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976baca-7b74-4caf-9183-4840695c8d9a",
   "metadata": {},
   "source": [
    "**Workflow complete!** Use CSVs for plotting/dashboarding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68473a93-e181-492a-8d76-95d84ae03c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-Jupyter_ml]",
   "language": "python",
   "name": "conda-env-.conda-Jupyter_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
